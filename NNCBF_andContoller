import torch
from torch import nn
import numpy as np

# Define a Control Barrier Function (CBF) neural network
class CBF(nn.Module):

    def __init__(self, state_dim, obstacle_dim, control_dim, preprocess=None):
        super().__init__()
        # Initialize class variables
        self.state_dim = state_dim
        self.obstacle_dim = obstacle_dim
        self.control_dim = control_dim
        self.preprocess = preprocess

        # Define convolutional layers used for feature extraction
        self.conv_layer0 = nn.Conv1d(state_dim, 64, 1)
        self.conv_layer1 = nn.Conv1d(64, 128, 1)
        self.conv_layer2 = nn.Conv1d(128, 128, 1)
        self.conv_layer3 = nn.Conv1d(128, 128, 1)
        self.conv_layer4 = nn.Conv1d(128, 1, 1)
        # Activation function (ReLU)
        self.activation_func = nn.ReLU()
        # Output activation function (Tanh)
        self.output_func = nn.Tanh()

    def forward(self, state, obstacle):
        """
        Args:
            state: Tensor of shape (batch_size, state_dim) representing the state.
            obstacle: Tensor of shape (batch_size, obstacle_dim, state_dim) representing obstacles.
        Returns:
            h: Tensor of shape (batch_size, obstacle_dim) representing the barrier function output.
        """
        # Unsqueeze the state to add a dimension for compatibility with Conv1d
        state = torch.unsqueeze(state, 2)    # (batch_size, state_dim, 1)
        # Permute the obstacle tensor dimensions to match the state dimensions
        obstacle = obstacle.permute(0, 2, 1) # (batch_size, state_dim, obstacle_dim)
        # Calculate the difference between the state and obstacles
        state_diff = state - obstacle

        # Apply optional preprocessing if provided
        if self.preprocess is not None:
            state_diff = self.preprocess(state_diff)

        # Pass through the convolutional layers with activation functions
        x = self.activation_func(self.conv_layer0(state_diff))
        x = self.activation_func(self.conv_layer1(x))
        x = self.activation_func(self.conv_layer2(x))   # (batch_size, 128, obstacle_dim)
        x = self.activation_func(self.conv_layer3(x))
        x = self.conv_layer4(x)
        # Squeeze the tensor to remove unnecessary dimensions
        h = torch.squeeze(x, dim=1)          # (batch_size, obstacle_dim)
        return h


# Define a neural network controller
class NNController(nn.Module):

    def __init__(self, state_dim, obstacle_dim, control_dim, preprocess=None, output_scale=1.0):
        super().__init__()
        # Initialize class variables
        self.state_dim = state_dim
        self.obstacle_dim = obstacle_dim
        self.control_dim = control_dim
        self.preprocess = preprocess

        # Define convolutional layers for feature extraction
        self.conv_layer0 = nn.Conv1d(state_dim, 64, 1)
        self.conv_layer1 = nn.Conv1d(64, 128, 1)
        self.conv_layer2 = nn.Conv1d(128, 128, 1)
        # Define fully connected layers for the controller output
        self.fc_layer0 = nn.Linear(128 + control_dim + state_dim, 128)
        self.fc_layer1 = nn.Linear(128, 64)
        self.fc_layer2 = nn.Linear(64, control_dim)
        # Activation function (ReLU)
        self.activation_func = nn.ReLU()
        # Output activation function (Tanh)
        self.output_func = nn.Tanh()
        # Output scaling factor
        self.output_scale = output_scale

    def forward(self, state, obstacle, nominal_control, state_error):
        """
        Args:
            state: Tensor of shape (batch_size, state_dim) representing the state.
            obstacle: Tensor of shape (batch_size, obstacle_dim, state_dim) representing obstacles.
            nominal_control: Tensor of shape (batch_size, control_dim) representing the nominal control input.
            state_error: Tensor of shape (batch_size, state_dim) representing the state error.
        Returns:
            control: Tensor of shape (batch_size, control_dim) representing the control output.
        """
        # Unsqueeze the state to add a dimension for compatibility with Conv1d
        state = torch.unsqueeze(state, 2)    # (batch_size, state_dim, 1)
        # Permute the obstacle tensor dimensions to match the state dimensions
        obstacle = obstacle.permute(0, 2, 1) # (batch_size, state_dim, obstacle_dim)
        # Calculate the difference between the state and obstacles
        state_diff = state - obstacle

        # Apply optional preprocessing if provided
        if self.preprocess is not None:
            state_diff = self.preprocess(state_diff)
            state_error = self.preprocess(state_error)

        # Pass through the convolutional layers with activation functions
        x = self.activation_func(self.conv_layer0(state_diff))
        x = self.activation_func(self.conv_layer1(x))
        x = self.activation_func(self.conv_layer2(x))   # (batch_size, 128, obstacle_dim)
        # Apply max pooling across obstacles to get a single feature vector
        x, _ = torch.max(x, dim=2)              # (batch_size, 128)
        # Concatenate state features, nominal control, and state error
        x = torch.cat([x, nominal_control, state_error], dim=1) # (batch_size, 128 + control_dim + state_dim)
        # Pass through fully connected layers with activation functions
        x = self.activation_func(self.fc_layer0(x))
        x = self.activation_func(self.fc_layer1(x))
        # Output control signal with scaling and add nominal control
        x = self.output_func(self.fc_layer2(x)) * self.output_scale
        control = x + nominal_control
        return control


# Define a control-affine dynamics model
class ControlAffineDynamics(nn.Module):

    def __init__(self, state_dim, control_dim, preprocess=None, extended_state_dim=0):
        super().__init__()
        # Initialize class variables
        self.state_dim = state_dim
        self.control_dim = control_dim
        self.preprocess = preprocess
        self.extended_state_dim = extended_state_dim

        # Define fully connected layers for the function f(s)
        self.f_fc_layer0 = nn.Linear(state_dim + extended_state_dim, 64)
        self.f_fc_layer1 = nn.Linear(64, 128)
        self.f_fc_layer2 = nn.Linear(128, state_dim)

        # Define fully connected layers for the function B(s)
        self.B_fc_layer0 = nn.Linear(state_dim + extended_state_dim, 64)
        self.B_fc_layer1 = nn.Linear(64, 128)
        self.B_fc_layer2 = nn.Linear(128, state_dim * control_dim)

        # Activation function (Tanh)
        self.activation_func = nn.Tanh()

    def forward(self, state, control):
        """ Compute f(s) and B(s) such that s_dot = f(s) + B(s)u.
        Args:
            state: Tensor of shape (batch_size, state_dim) representing the state.
            control: Tensor of shape (batch_size, control_dim) representing the control input.
        Returns:
            f: Tensor of shape (batch_size, state_dim) representing the dynamics function f(s).
            B: Tensor of shape (batch_size, state_dim, control_dim) representing the control matrix B(s).
        """
        # Apply optional preprocessing if provided
        if self.preprocess is not None:
            state = self.preprocess(state) # (batch_size, state_dim + extended_state_dim)

        # Compute f(s) using the fully connected layers
        x = self.activation_func(self.f_fc_layer0(state))
        x = self.activation_func(self.f_fc_layer1(x))
        f = self.f_fc_layer2(x)

        # Compute B(s) using the fully connected layers
        x = self.activation_func(self.B_fc_layer0(state))
        x = self.activation_func(self.B_fc_layer1(x))
        B = self.B_fc_layer2(x).view(-1, self.state_dim, self.control_dim)

        return f, B
