import torch
import torch.nn as nn
import torch.optim as optim

# -------------------------
# CBF Definition
# -------------------------
class CBF(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(CBF, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
    
    def forward(self, state, observation):
        x = torch.cat([state, observation], dim=-1)
        return self.net(x)  # Scalar CBF value

# -------------------------
# Controller Definition
# -------------------------
class Controller(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(Controller, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )
    
    def forward(self, state, observation):
        x = torch.cat([state, observation], dim=-1)
        return self.net(x)  # Control action

# -------------------------
# Loss Functions
# -------------------------
def cbf_loss(cbf_model, states, observations, actions, safe_states, unsafe_states):
    # CBF Conditions
    safe_loss = torch.relu(-cbf_model(safe_states, observations))  # h(s) >= 0
    unsafe_loss = torch.relu(cbf_model(unsafe_states, observations) + 1e-2)  # h(s) < 0

    # Gradient condition
    gradients = torch.autograd.grad(
        cbf_model(states, observations), states, grad_outputs=torch.ones_like(states),
        create_graph=True
    )[0]
    gradient_loss = torch.relu(-gradients @ actions)

    return safe_loss.mean() + unsafe_loss.mean() + gradient_loss.mean()

def controller_loss(controller_model, cbf_model, states, observations, actions_ref):
    # Task loss
    actions = controller_model(states, observations)
    task_loss = ((actions - actions_ref) ** 2).mean()

    # CBF regularization
    cbf_values = cbf_model(states, observations)
    safety_loss = torch.relu(-cbf_values).mean()

    return task_loss + 1e-2 * safety_loss

# -------------------------
# Training Loop
# -------------------------
def train(cbf_model, controller_model, env, optimizer, epochs):
    for epoch in range(epochs):
        # Sample data from the environment
        states, observations, actions_ref, safe_states, unsafe_states = env.sample_data()

        # Compute losses
        cbf_loss_value = cbf_loss(cbf_model, states, observations, actions_ref, safe_states, unsafe_states)
        controller_loss_value = controller_loss(controller_model, cbf_model, states, observations, actions_ref)

        # Update models
        optimizer.zero_grad()
        total_loss = cbf_loss_value + controller_loss_value
        total_loss.backward()
        optimizer.step()

        print(f"Epoch {epoch}: Total Loss = {total_loss.item()}")

# -------------------------
# Test and Refine Control
# -------------------------
def refine_control(cbf_model, controller_model, state, observation):
    action = controller_model(state, observation)
    cbf_value = cbf_model(state, observation)
    
    if cbf_value < 0:
        # Refine action to satisfy CBF conditions
        action += torch.relu(-cbf_value)
    return action

# -------------------------
# Environment Simulation Stub
# -------------------------
class Environment:
    def __init__(self, state_dim, obs_dim, action_dim):
        self.state_dim = state_dim
        self.obs_dim = obs_dim
        self.action_dim = action_dim

    def sample_data(self, batch_size=128):
        # Simulate environment data (replace with actual simulation)
        states = torch.rand(batch_size, self.state_dim)
        observations = torch.rand(batch_size, self.obs_dim)
        actions_ref = torch.rand(batch_size, self.action_dim)
        safe_states = torch.rand(batch_size, self.state_dim) * 0.5
        unsafe_states = torch.rand(batch_size, self.state_dim) * -0.5
        return states, observations, actions_ref, safe_states, unsafe_states

# -------------------------
# Main Script
# -------------------------
if __name__ == "__main__":
    # Environment settings
    state_dim = 4
    obs_dim = 4
    action_dim = 2
    hidden_dim = 64

    # Initialize models
    cbf_model = CBF(state_dim + obs_dim, hidden_dim)
    controller_model = Controller(state_dim + obs_dim, hidden_dim, action_dim)

    # Environment and optimizer
    env = Environment(state_dim, obs_dim, action_dim)
    optimizer = optim.Adam(list(cbf_model.parameters()) + list(controller_model.parameters()), lr=1e-3)

    # Train models
    epochs = 50
    train(cbf_model, controller_model, env, optimizer, epochs)

    # Test and refine control
    test_state = torch.rand(1, state_dim)
    test_observation = torch.rand(1, obs_dim)
    refined_action = refine_control(cbf_model, controller_model, test_state, test_observation)
    print("Refined Action:", refined_action)
